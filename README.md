# BERT-Model-Distillation

Deployed BERT 12 model for sentimental analysis on Amazon reviews on EC2 instance.

The data used for training can be found in the Data folder and the saved models and weights can be found in the Model Files

The TextBlob Baseline notebook contains the code where we use TextBlob for sentiment classification on the data available in the Data Folder
